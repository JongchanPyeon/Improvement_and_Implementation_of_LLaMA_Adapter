{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d60d11-f4cd-4515-8888-3eadf194a52f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/test\n"
     ]
    }
   ],
   "source": [
    "%cd test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa2a65-3216-4f6a-87e9-f1bdd20473fa",
   "metadata": {},
   "source": [
    "# 1. Download \"LLaMA-7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692def30-f1bb-4c44-a79a-f097ecced7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Download the repository\n",
    "repo_id = \"nyanko7/LLaMA-7B\"\n",
    "local_dir = \"./LLaMA-7B\"  # Directory to save the files\n",
    "snapshot_download(repo_id, local_dir=local_dir)\n",
    "\n",
    "print(f\"All files downloaded to: {local_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc6eee7-154d-45ac-8a26-9f3446d7ee22",
   "metadata": {},
   "source": [
    "# 2. Download \"COCO2014\"\n",
    "- Train2014 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5394ea-69b7-4dbe-a27c-767e7560700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir coco2014\n",
    "!wget http://images.cocodataset.org/zips/train2014.zip\n",
    "!unzip train2014.zip -d coco2014/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ee9b9-00f7-4949-8a2f-459270a4020b",
   "metadata": {},
   "source": [
    "# 3. Download \"alpaca_gpt4_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91111cc6-8432-4741-9ecd-c7cd6f3ac872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved as alpaca_gpt4_data.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Raw URL of the file\n",
    "url = \"https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/alpaca_gpt4_data.json\"\n",
    "# Local filename to save the file\n",
    "filename = \"LLaMA-Adapter_replicated/llama_adapter_v2_multimodal7b/alpaca_gpt4_data.json\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Open the file in write mode and save the content\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk.decode(\"utf-8\"))\n",
    "    print(f\"File downloaded successfully and saved as {filename}\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136a724-7199-475c-8a9d-4b9c3db62bd8",
   "metadata": {},
   "source": [
    "# 4. Download \"llava_instruct_150k.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca005144-2144-42c6-8386-5e148c2e4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "file_url = \"https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K/resolve/main/llava_instruct_150k.json\"\n",
    "output_file = \"llava_instruct_150k.json\"\n",
    "response = requests.get(file_url)\n",
    "if response.status_code == 200:  # Check if the request was successful\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"File downloaded and saved as '{output_file}'.\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503e4dc-edc0-49bb-8e7a-cb9b36ec4ca5",
   "metadata": {},
   "source": [
    "# 5. Update \"llava_instruct_150k.json\" to reassign \"image\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb272ea4-df82-4de4-977a-106043e34db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "json_path = \"llava_instruct_150k.json\"\n",
    "image_folder = \"coco2014/train2014\"\n",
    "output_json_path = \"LLaMA-Adapter_replicated/llama_adapter_v2_multimodal7b/updated_llava_instruct_150k.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Update the image paths\n",
    "for entry in data:\n",
    "    # Original image name\n",
    "    image_name = entry[\"image\"]\n",
    "    # Format the image path to match the required structure\n",
    "    entry[\"image\"] = os.path.join(image_folder, f\"COCO_train2014_{image_name.split('.')[0]}.jpg\")\n",
    "\n",
    "# Save the updated JSON to a new file\n",
    "with open(output_json_path, 'w') as file:\n",
    "    json.dump(data, file, indent=2)\n",
    "\n",
    "print(f\"Updated JSON saved to: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f2f5f-1cde-4d11-9299-30c2017d3219",
   "metadata": {},
   "source": [
    "# 6. Download the pre-trained 7B model\n",
    "- Pre-trained on Image-Text-V1, which is a concatenation of LAION400M, COYO, MMC4, SBU, Conceptual Captions, and COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30b7f6-731c-4864-99e5-588a7ac660b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O 7B-pretrained.pth \"https://huggingface.co/Cxxs/ImageBind-LLM/resolve/main/7B-pretrained.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac820b-c95b-4484-b97d-29acf3300386",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3134eb-83ff-46aa-93d0-93080d930b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd LLaMA-Adapter_replicated/llama_adapter_v2_multimodal7b\n",
    "!pip install -r requirements.txt\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e5649-6d7e-4a02-85ac-010c1454e36d",
   "metadata": {},
   "source": [
    "# 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868fc52-a0a5-4677-90f2-8a4e21ed5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u LLaMA-Adapter_replicated/llama_adapter_v2_multimodal7b/main_finetune.py --data_config LLaMA-Adapter_replicated/llama_adapter_v2_multimodal7b/finetune_data_config.yaml \\\n",
    " --batch_size 4 \\\n",
    " --epochs 4 --warmup_epochs 1 --blr 10e-4 --weight_decay 0.02 \\\n",
    " --llama_path LLaMA-7B \\\n",
    " --output_dir Output \\\n",
    " --pretrained_path 7B-pretrained.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88edb458-5c02-437e-8dec-066dd8350e14",
   "metadata": {},
   "source": [
    "# 9. Resume training (Optional; if the training was stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a37a1-5a2d-4a91-bdcb-c9ea35f1c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u LLaMA-Adapter_replicated/llama_adapter_v2_multimodal7b/main_finetune.py --data_config LLaMA-Adapter_replicated/llama_adapter_v2_multimodal7b/finetune_data_config.yaml \\\n",
    " --batch_size 4 \\\n",
    " --epochs 4 --warmup_epochs 1 --blr 10e-4 --weight_decay 0.02 \\\n",
    " --llama_path LLaMA-7B \\\n",
    " --output_dir Output \n",
    " --pretrained_path /path/to/checkpoint.pth \\\n",
    " --start_epoch [epoch]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
